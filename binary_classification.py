# -*- coding: utf-8 -*-
"""Binary_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ikt3taF1cn0Y_IIZ1PEOxJaxO4_sTkaU
"""

from google.colab import drive
drive.mount('/content/gdrive')

import math
import numpy
import matplotlib.pyplot as plt
from pandas import read_csv
from keras.models import Sequential
from keras import regularizers
from keras.layers import *
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from keras.optimizers import RMSprop
from keras.initializers import glorot_uniform, glorot_normal, RandomUniform
import sys
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from datetime import timedelta
from sklearn.externals import joblib 
import datetime

def Clean(data,valid = False):
  data2 = data.index
  data = data.values
  new_data = []
  for i in range(len(data)):
    if(str(data[i][0]) == str(1e400*0)):
      if(str(data2[i][-1]) != str(1e400*0)):
        new_line3 = list(map(str,data2[i][2].split(';')))   
        if len(new_line3) == 17:
          new_line1 = list(map(str,data2[i][0].split(';')))
          new_line2 = list(map(str,data2[i][1].split(';')))
          new_data.append(new_line1 + new_line2 + new_line3[:6]+['']+new_line3[6:]) 
          pass
        pass
      pass
    else:
      new_line1 = list(map(str,data2[i][0].split(';')))
      new_line2 = list(map(str,data2[i][1].split(';')))
      new_line3 = list(map(str,data2[i][2].split(';')))      
      new_line4 = list(map(str,data[i][0].split(';')))
      
      new_data.append(new_line1 + new_line2 + new_line3 + new_line4)
#       print(new_line1 + new_line2 + new_line3 + new_line4)
  data = pd.DataFrame(new_data,columns=['v0','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17','v18','v19','v20','target'])
  data.to_csv("data.csv",index=False)
  data = pd.read_csv("/content/data.csv")
  return data

data = pd.read_csv("/content/gdrive/My Drive/Colab Notebooks/binary_classification/training.csv")
print(len(data))
data = Clean(data)
print(len(data))
data.head()

for i in data:
  if (len(data[i].unique()) < 50):
    print(i,data[i].unique())

def Prepare(data):
  data['v0'] = data['v0'].fillna(50)
  data['v7'] = data['v7'].fillna(50)
  data['v8'] = data['v8'].fillna(50)
  data['v19'] = data['v19'].fillna(50)
  
  for i in range(len(data['v0'].unique())):
    data['v0'] = data['v0'].replace(data['v0'].unique()[i],i)
  
  for i in range(len(data['v5'].unique())):
    data['v5'] = data['v5'].replace(data['v5'].unique()[i],i)

  for i in range(len(data['v6'].unique())):
    data['v6'] = data['v6'].replace(data['v6'].unique()[i],i)

  for i in range(len(data['v7'].unique())):
    data['v7'] = data['v7'].replace(data['v7'].unique()[i],i)

  for i in range(len(data['v8'].unique())):
    data['v8'] = data['v8'].replace(data['v8'].unique()[i],i)
    
  for i in range(len(data['v11'].unique())):
    data['v11'] = data['v11'].replace(data['v11'].unique()[i],i)
    
  for i in range(len(data['v12'].unique())):
    data['v12'] = data['v12'].replace(data['v12'].unique()[i],i)
    
  for i in range(len(data['v14'].unique())):
    data['v14'] = data['v14'].replace(data['v14'].unique()[i],i)
    
  for i in range(len(data['v15'].unique())):
    data['v15'] = data['v15'].replace(data['v15'].unique()[i],i)
    
  for i in range(len(data['v19'].unique())):
    data['v19'] = data['v19'].replace(data['v19'].unique()[i],i)
    
  for i in range(len(data['target'].unique())):
    data['target'] = data['target'].replace(data['target'].unique()[i],i)
  data = data.fillna(data.mean())
  return data

data = Prepare(data)
data.head()

y = data['target']
x = data.drop(['target'],axis=1)
x.shape,y.shape

scaler = StandardScaler()
x = scaler.fit_transform(x)
x.shape

activ_func = 'tanh'  
loss = 'binary_crossentropy'                  
optimizer="adam"              
dropout = 0.05

model = Sequential()
model.add(Dense(256,input_dim=np.shape(x)[1],activation=activ_func,kernel_regularizer=regularizers.l2(0.001)))
model.add(Dense(128,activation=activ_func))
model.add(Dense(units=1,activation = 'sigmoid'))
model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])
model.summary()

model.fit(np.array(x), np.array(y), epochs=1, batch_size=128, verbose=1)

valid = pd.read_csv("/content/gdrive/My Drive/Colab Notebooks/binary_classification/validation.csv")
valid = Clean(valid)
valid = Prepare(valid)
print(valid.head())
valid_y = valid['target']
valid_x = valid.drop(['target'],axis=1)
valid_x.shape,valid_y.shape

from sklearn.metrics import precision_recall_fscore_support
y_pred = model.predict_classes(valid_x)
result = precision_recall_fscore_support(valid_y, y_pred,average='binary')
print('precision=',result[0],'recall=',result[1], 'f1score=',result[2])