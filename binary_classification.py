# -*- coding: utf-8 -*-
"""Binary classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f85S8gXM2BzFjky9lMk-e03e8gif40eh
"""

from google.colab import drive
drive.mount('/content/gdrive')

import math
import numpy
import matplotlib.pyplot as plt
from pandas import read_csv
from keras.models import Sequential
from keras import regularizers
from keras.layers import *
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from keras.optimizers import RMSprop
from keras.initializers import glorot_uniform, glorot_normal, RandomUniform
import sys
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from datetime import timedelta
from sklearn.externals import joblib 
import datetime

def Clean(data,valid = False):
  data = data.values
  new_data = []
  for i in range(len(data)):
    if(str(data[i][0]) == str(1e400*0)):
      pass
    else:
      new_line = list(map(str,data[i][0].split(';')))
      new_data.append(new_line)

  data = pd.DataFrame(new_data,columns=['v0','v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','target'])
  data.to_csv("data.csv",index=False)
  data = pd.read_csv("/content/data.csv")

  return data

data = pd.read_csv("/content/gdrive/My Drive/Colab Notebooks/binary_classification/training.csv")
data = Clean(data)
data.head()

for i in data:
  if (len(data[i].unique()) < 5):
    print(i,data[i].unique())

def Prepare(data):
  data['v9'] = data['v9'].fillna(2)
  data['v6'] = data['v6'].fillna(0)
  data['v8'] = data['v8'].fillna(0)
  
  for i in range(len(data['v1'].unique())):
    data['v1'] = data['v1'].replace(data['v1'].unique()[i],i)
  
  for i in range(len(data['v2'].unique())):
    data['v2'] = data['v2'].replace(data['v2'].unique()[i],i)

  for i in range(len(data['v4'].unique())):
    data['v4'] = data['v4'].replace(data['v4'].unique()[i],i)

  for i in range(len(data['v5'].unique())):
    data['v5'] = data['v5'].replace(data['v5'].unique()[i],i)

  for i in range(len(data['v9'].unique())):
    data['v9'] = data['v9'].replace(data['v9'].unique()[i],i)

  for i in range(len(data['target'].unique())):
    data['target'] = data['target'].replace(data['target'].unique()[i],i)
  
  return data

data = Prepare(data)

y = data['target']
x = data.drop(['target'],axis=1)
x.shape,y.shape

scaler = StandardScaler()
x = scaler.fit_transform(x)
x.shape

neurons = 512                 
activ_func = 'tanh'  
loss = 'binary_crossentropy'                  
optimizer="adam"              
dropout = 0.05

model = Sequential()
model.add(Dense(512,input_dim=np.shape(x)[1],activation=activ_func))
model.add(Dense(256,activation=activ_func))
model.add(Dense(units=1,activation = 'sigmoid'))
model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])
model.summary()

model.fit(np.array(x), np.array(y), epochs=2, batch_size=32, verbose=1)

valid = pd.read_csv("/content/gdrive/My Drive/Colab Notebooks/binary_classification/validation.csv")
valid = Clean(valid)
valid = Prepare(valid)
print(valid.head())
valid_y = data['target']
valid_x = data.drop(['target'],axis=1)
valid_x.shape,valid_y.shape

from sklearn.metrics import precision_recall_fscore_support
y_pred = model.predict_classes(valid_x)
result = precision_recall_fscore_support(valid_y, y_pred,average='binary')
print('precision=',result[0],'recall=',result[1], 'f1score=',result[2])